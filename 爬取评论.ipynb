import pandas as pd
import requests
def getHTML(url):
    try:
        r=requests.get(url,timeout=30)
        r.raise_for_status()  # 如果状态不是200, 引发HTTPError异常
        r.encoding = r.apparent_encoding
        return r.text
    except:
        return "产生异常"
import json
import time
import re
def parserHTML(html):
    commentlist=[]
    hlist=[]
    hlist.append("名字")
    hlist.append("性别")
    hlist.append("时间")
    hlist.append("评论")
    hlist.append("点赞数")
    hlist.append("回复数")
    commentlist.append(hlist)
    #解析获得的数据，包括评论内容，评论时间，用户ID等
    s=json.loads(html)
    for i in range(20):
        comment=s['data']['replies'][i]
        # 用户名，性别，时间，评价，点赞数，回复数
        blist=[]
        username=comment['member']['uname']
        sex=comment['member']['sex']
        ctime=time.strftime("%Y-%m-%d %H:%M:%S",time.localtime(comment['ctime']))
        content=comment['content']['message']
        likes=comment['like']
        rcounts=comment['rcount']
        blist.append(username)
        blist.append(sex)
        blist.append(ctime)
        blist.append(content)
        blist.append(likes)
        blist.append(rcounts)
        commentlist.append(blist)
    writePage(commentlist)
        #用正则表达式过滤掉非中文字符
        #pattern = ".*?([\u4E00-\u9FA5]+)"
        #match_obj = re.match(pattern,content)
        #print(match_obj.group(0))
def writePage(urating):
    #将爬取的数据存入本地文件中
    dataframe = pd.DataFrame(urating)
    dataframe.to_csv('C:\\Users\\zzlw_\\Desktop\\bilibili.csv', mode='a', index=False, sep=',', header=False)
if __name__ == '__main__':
    for page in range(2,1000):
        url='https://api.bilibili.com/x/v2/reply?type=1&oid=56944704&pn='+str(page)
        html=getHTML(url)
        parserHTML(html)
